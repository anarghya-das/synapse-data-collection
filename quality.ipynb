{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal, stats\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EEGSignalQuality:\n",
    "    \"\"\"\n",
    "    Comprehensive signal quality assessment for around-the-ear EEG devices.\n",
    "    Designed for academic research with MNE Python raw objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raw, ear_channels, reference_channels=None):\n",
    "        \"\"\"\n",
    "        Initialize signal quality analyzer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        raw : mne.io.Raw\n",
    "            MNE raw object containing EEG data\n",
    "        ear_channels : list\n",
    "            List of ear-EEG channel names (e.g., ['ear_left', 'ear_right'])\n",
    "        reference_channels : list, optional\n",
    "            List of reference scalp channel names for comparison\n",
    "        \"\"\"\n",
    "        self.raw = raw.copy()\n",
    "        self.ear_channels = ear_channels\n",
    "        self.reference_channels = reference_channels or []\n",
    "        self.sfreq = raw.info['sfreq']\n",
    "        self.results = {}\n",
    "        \n",
    "    def calculate_rms(self, channels=None, window_size=1.0):\n",
    "        \"\"\"\n",
    "        Calculate Root Mean Square (RMS) for signal amplitude assessment.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        channels : list, optional\n",
    "            Channels to analyze (default: ear_channels)\n",
    "        window_size : float\n",
    "            Window size in seconds for RMS calculation\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : RMS values and statistics\n",
    "        \"\"\"\n",
    "        if channels is None:\n",
    "            channels = self.ear_channels\n",
    "            \n",
    "        data, times = self.raw[channels, :]\n",
    "        window_samples = int(window_size * self.sfreq)\n",
    "        \n",
    "        rms_results = {}\n",
    "        for i, ch in enumerate(channels):\n",
    "            ch_data = data[i, :]\n",
    "            # Calculate windowed RMS\n",
    "            rms_windows = []\n",
    "            for start in range(0, len(ch_data) - window_samples, window_samples):\n",
    "                window_data = ch_data[start:start + window_samples]\n",
    "                rms_val = np.sqrt(np.mean(window_data ** 2))\n",
    "                rms_windows.append(rms_val)\n",
    "            \n",
    "            rms_results[ch] = {\n",
    "                'mean_rms': np.mean(rms_windows),\n",
    "                'std_rms': np.std(rms_windows),\n",
    "                'rms_windows': rms_windows,\n",
    "                'stability_score': 1 / (1 + np.std(rms_windows))  # Higher = more stable\n",
    "            }\n",
    "            \n",
    "        return rms_results\n",
    "    \n",
    "    def calculate_snr_alpha(self, channels=None, eyes_closed_segments=None):\n",
    "        \"\"\"\n",
    "        Calculate Signal-to-Noise Ratio using alpha peak detection.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        channels : list, optional\n",
    "            Channels to analyze\n",
    "        eyes_closed_segments : list of tuples, optional\n",
    "            [(start_time, end_time), ...] for eyes-closed segments\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : SNR values and alpha power metrics\n",
    "        \"\"\"\n",
    "        if channels is None:\n",
    "            channels = self.ear_channels\n",
    "            \n",
    "        # Apply minimal preprocessing for spectral analysis\n",
    "        raw_filtered = self.raw.copy().filter(l_freq=0.5, h_freq=None)\n",
    "        raw_filtered.notch_filter(freqs=[50, 60])  # Remove line noise\n",
    "        \n",
    "        snr_results = {}\n",
    "        \n",
    "        for ch in channels:\n",
    "            data, times = raw_filtered[ch, :]\n",
    "            data = data.flatten()\n",
    "            \n",
    "            # Calculate power spectral density\n",
    "            freqs, psd = signal.welch(data, fs=self.sfreq, nperseg=int(4*self.sfreq))\n",
    "            \n",
    "            # Define frequency bands\n",
    "            alpha_band = (8, 13)\n",
    "            noise_bands = [(1, 4), (15, 25)]  # Delta and beta as noise reference\n",
    "            \n",
    "            # Find alpha peak\n",
    "            alpha_mask = (freqs >= alpha_band[0]) & (freqs <= alpha_band[1])\n",
    "            alpha_power = np.mean(psd[alpha_mask])\n",
    "            alpha_peak_freq = freqs[alpha_mask][np.argmax(psd[alpha_mask])]\n",
    "            \n",
    "            # Calculate noise power\n",
    "            noise_power = 0\n",
    "            for noise_band in noise_bands:\n",
    "                noise_mask = (freqs >= noise_band[0]) & (freqs <= noise_band[1])\n",
    "                noise_power += np.mean(psd[noise_mask])\n",
    "            noise_power /= len(noise_bands)\n",
    "            \n",
    "            # SNR calculation\n",
    "            snr_db = 10 * np.log10(alpha_power / noise_power)\n",
    "            \n",
    "            snr_results[ch] = {\n",
    "                'snr_db': snr_db,\n",
    "                'alpha_power': alpha_power,\n",
    "                'alpha_peak_freq': alpha_peak_freq,\n",
    "                'noise_power': noise_power,\n",
    "                'psd': psd,\n",
    "                'freqs': freqs\n",
    "            }\n",
    "            \n",
    "        return snr_results\n",
    "    \n",
    "    def calculate_spectral_power(self, channels=None):\n",
    "        \"\"\"\n",
    "        Calculate power spectral density across canonical EEG frequency bands.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Power values for each frequency band\n",
    "        \"\"\"\n",
    "        if channels is None:\n",
    "            channels = self.ear_channels\n",
    "            \n",
    "        # Apply filtering for spectral analysis\n",
    "        raw_filtered = self.raw.copy().filter(l_freq=0.5, h_freq=40)\n",
    "        raw_filtered.notch_filter(freqs=[50, 60])\n",
    "        \n",
    "        # Define frequency bands\n",
    "        bands = {\n",
    "            'delta': (0.5, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 13),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 40)\n",
    "        }\n",
    "        \n",
    "        spectral_results = {}\n",
    "        \n",
    "        for ch in channels:\n",
    "            data, times = raw_filtered[ch, :]\n",
    "            data = data.flatten()\n",
    "            \n",
    "            # Calculate PSD using multitaper method for better variance reduction\n",
    "            freqs, psd = signal.welch(data, fs=self.sfreq, nperseg=int(4*self.sfreq))\n",
    "            \n",
    "            ch_bands = {}\n",
    "            total_power = np.sum(psd)\n",
    "            \n",
    "            for band_name, (low, high) in bands.items():\n",
    "                band_mask = (freqs >= low) & (freqs <= high)\n",
    "                absolute_power = np.sum(psd[band_mask])\n",
    "                relative_power = absolute_power / total_power\n",
    "                \n",
    "                ch_bands[band_name] = {\n",
    "                    'absolute_power': absolute_power,\n",
    "                    'relative_power': relative_power,\n",
    "                    'peak_freq': freqs[band_mask][np.argmax(psd[band_mask])]\n",
    "                }\n",
    "            \n",
    "            spectral_results[ch] = ch_bands\n",
    "            \n",
    "        return spectral_results\n",
    "    \n",
    "    def calculate_cross_correlation(self, reference_channel=None):\n",
    "        \"\"\"\n",
    "        Calculate cross-correlation between ear-EEG and reference channels.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        reference_channel : str, optional\n",
    "            Reference channel name (e.g., scalp electrode)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Correlation coefficients and lag information\n",
    "        \"\"\"\n",
    "        if not reference_channel or reference_channel not in self.raw.ch_names:\n",
    "            print(\"Warning: No valid reference channel provided\")\n",
    "            return {}\n",
    "            \n",
    "        correlation_results = {}\n",
    "        \n",
    "        # Use filtered data for correlation analysis\n",
    "        raw_filtered = self.raw.copy().filter(l_freq=1, h_freq=40)\n",
    "        \n",
    "        ref_data, _ = raw_filtered[reference_channel, :]\n",
    "        ref_data = ref_data.flatten()\n",
    "        \n",
    "        for ch in self.ear_channels:\n",
    "            ear_data, _ = raw_filtered[ch, :]\n",
    "            ear_data = ear_data.flatten()\n",
    "            \n",
    "            # Pearson correlation\n",
    "            pearson_r, pearson_p = stats.pearsonr(ear_data, ref_data)\n",
    "            \n",
    "            # Cross-correlation with lags\n",
    "            cross_corr = np.correlate(ear_data, ref_data, mode='full')\n",
    "            lags = signal.correlation_lags(len(ear_data), len(ref_data), mode='full')\n",
    "            max_corr_idx = np.argmax(np.abs(cross_corr))\n",
    "            max_lag_samples = lags[max_corr_idx]\n",
    "            max_lag_ms = (max_lag_samples / self.sfreq) * 1000\n",
    "            \n",
    "            correlation_results[ch] = {\n",
    "                'pearson_r': pearson_r,\n",
    "                'pearson_p': pearson_p,\n",
    "                'max_cross_corr': cross_corr[max_corr_idx],\n",
    "                'optimal_lag_ms': max_lag_ms,\n",
    "                'cross_corr': cross_corr,\n",
    "                'lags': lags\n",
    "            }\n",
    "            \n",
    "        return correlation_results\n",
    "    \n",
    "    def calculate_coherence(self, reference_channel=None):\n",
    "        \"\"\"\n",
    "        Calculate coherence between ear-EEG and reference channels.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Coherence values across frequency bands\n",
    "        \"\"\"\n",
    "        if not reference_channel or reference_channel not in self.raw.ch_names:\n",
    "            print(\"Warning: No valid reference channel provided\")\n",
    "            return {}\n",
    "            \n",
    "        coherence_results = {}\n",
    "        raw_filtered = self.raw.copy().filter(l_freq=1, h_freq=40)\n",
    "        \n",
    "        ref_data, _ = raw_filtered[reference_channel, :]\n",
    "        ref_data = ref_data.flatten()\n",
    "        \n",
    "        for ch in self.ear_channels:\n",
    "            ear_data, _ = raw_filtered[ch, :]\n",
    "            ear_data = ear_data.flatten()\n",
    "            \n",
    "            # Calculate coherence\n",
    "            freqs, coherence = signal.coherence(ear_data, ref_data, \n",
    "                                               fs=self.sfreq, nperseg=int(4*self.sfreq))\n",
    "            \n",
    "            # Calculate coherence in frequency bands\n",
    "            bands = {\n",
    "                'delta': (0.5, 4), 'theta': (4, 8), 'alpha': (8, 13),\n",
    "                'beta': (13, 30), 'gamma': (30, 40)\n",
    "            }\n",
    "            \n",
    "            band_coherence = {}\n",
    "            for band_name, (low, high) in bands.items():\n",
    "                band_mask = (freqs >= low) & (freqs <= high)\n",
    "                band_coherence[band_name] = np.mean(coherence[band_mask])\n",
    "            \n",
    "            coherence_results[ch] = {\n",
    "                'band_coherence': band_coherence,\n",
    "                'mean_coherence': np.mean(coherence),\n",
    "                'max_coherence': np.max(coherence),\n",
    "                'coherence_spectrum': coherence,\n",
    "                'freqs': freqs\n",
    "            }\n",
    "            \n",
    "        return coherence_results\n",
    "    \n",
    "    def detect_artifacts(self, channels=None, voltage_threshold=100e-6):\n",
    "        \"\"\"\n",
    "        Detect artifacts using voltage threshold and gradient criteria.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        channels : list, optional\n",
    "            Channels to analyze\n",
    "        voltage_threshold : float\n",
    "            Voltage threshold in volts (default: 100 ÂµV)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Artifact detection results\n",
    "        \"\"\"\n",
    "        if channels is None:\n",
    "            channels = self.ear_channels\n",
    "            \n",
    "        artifact_results = {}\n",
    "        \n",
    "        for ch in channels:\n",
    "            data, times = self.raw[ch, :]\n",
    "            data = data.flatten()\n",
    "            \n",
    "            # Voltage threshold artifacts\n",
    "            voltage_artifacts = np.abs(data) > voltage_threshold\n",
    "            \n",
    "            # Gradient artifacts (rapid voltage changes)\n",
    "            gradient = np.gradient(data)\n",
    "            gradient_threshold = 5 * np.std(gradient)\n",
    "            gradient_artifacts = np.abs(gradient) > gradient_threshold\n",
    "            \n",
    "            # Combined artifact mask\n",
    "            all_artifacts = voltage_artifacts | gradient_artifacts\n",
    "            artifact_proportion = np.sum(all_artifacts) / len(data)\n",
    "            \n",
    "            # Artifact-free segments\n",
    "            clean_data = data[~all_artifacts]\n",
    "            \n",
    "            artifact_results[ch] = {\n",
    "                'artifact_proportion': artifact_proportion,\n",
    "                'voltage_artifacts': np.sum(voltage_artifacts),\n",
    "                'gradient_artifacts': np.sum(gradient_artifacts),\n",
    "                'clean_data_length': len(clean_data),\n",
    "                'artifact_mask': all_artifacts,\n",
    "                'data_quality_score': 1 - artifact_proportion,\n",
    "            }\n",
    "            \n",
    "        return artifact_results\n",
    "    \n",
    "    def alpha_modulation_test(self, eyes_open_segments, eyes_closed_segments):\n",
    "        \"\"\"\n",
    "        Test alpha rhythm modulation (eyes-open vs eyes-closed).\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        eyes_open_segments : list of tuples\n",
    "            [(start_time, end_time), ...] for eyes-open periods\n",
    "        eyes_closed_segments : list of tuples\n",
    "            [(start_time, end_time), ...] for eyes-closed periods\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Alpha modulation results\n",
    "        \"\"\"\n",
    "        raw_filtered = self.raw.copy().filter(l_freq=1, h_freq=30)\n",
    "        raw_filtered.notch_filter(freqs=[50, 60])\n",
    "        \n",
    "        modulation_results = {}\n",
    "        \n",
    "        for ch in self.ear_channels:\n",
    "            # Extract alpha power for each condition\n",
    "            alpha_power_open = []\n",
    "            alpha_power_closed = []\n",
    "            \n",
    "            # Eyes open segments\n",
    "            for start_time, end_time in eyes_open_segments:\n",
    "                start_sample = int(start_time * self.sfreq)\n",
    "                end_sample = int(end_time * self.sfreq)\n",
    "                segment_data = raw_filtered[ch, start_sample:end_sample][0].flatten()\n",
    "                \n",
    "                freqs, psd = signal.welch(segment_data, fs=self.sfreq)\n",
    "                alpha_mask = (freqs >= 8) & (freqs <= 13)\n",
    "                alpha_power_open.append(np.mean(psd[alpha_mask]))\n",
    "            \n",
    "            # Eyes closed segments\n",
    "            for start_time, end_time in eyes_closed_segments:\n",
    "                start_sample = int(start_time * self.sfreq)\n",
    "                end_sample = int(end_time * self.sfreq)\n",
    "                segment_data = raw_filtered[ch, start_sample:end_sample][0].flatten()\n",
    "                \n",
    "                freqs, psd = signal.welch(segment_data, fs=self.sfreq)\n",
    "                alpha_mask = (freqs >= 8) & (freqs <= 13)\n",
    "                alpha_power_closed.append(np.mean(psd[alpha_mask]))\n",
    "            \n",
    "            # Statistical comparison\n",
    "            alpha_power_open = np.array(alpha_power_open)\n",
    "            alpha_power_closed = np.array(alpha_power_closed)\n",
    "            \n",
    "            stat, p_value = stats.wilcoxon(alpha_power_open, alpha_power_closed,\n",
    "                                         alternative='less')\n",
    "            \n",
    "            modulation_ratio = np.mean(alpha_power_closed) / np.mean(alpha_power_open)\n",
    "            \n",
    "            modulation_results[ch] = {\n",
    "                'alpha_power_eyes_open': np.mean(alpha_power_open),\n",
    "                'alpha_power_eyes_closed': np.mean(alpha_power_closed),\n",
    "                'modulation_ratio': modulation_ratio,\n",
    "                'statistical_significance': p_value,\n",
    "                'modulation_detected': p_value < 0.05 and modulation_ratio > 1.2,\n",
    "            }\n",
    "            \n",
    "        return modulation_results\n",
    "    \n",
    "    def comprehensive_quality_assessment(self, reference_channel=None):\n",
    "        \"\"\"\n",
    "        Run comprehensive signal quality assessment.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Complete quality assessment results\n",
    "        \"\"\"\n",
    "        print(\"Running comprehensive EEG signal quality assessment...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. RMS Analysis\n",
    "        print(\"1. Calculating RMS...\")\n",
    "        results['rms'] = self.calculate_rms()\n",
    "        \n",
    "        # 2. SNR Analysis\n",
    "        print(\"2. Calculating SNR...\")\n",
    "        results['snr'] = self.calculate_snr_alpha()\n",
    "        \n",
    "        # 3. Spectral Power Analysis\n",
    "        print(\"3. Analyzing spectral power...\")\n",
    "        results['spectral_power'] = self.calculate_spectral_power()\n",
    "        \n",
    "        # 4. Cross-correlation (if reference available)\n",
    "        if reference_channel:\n",
    "            print(\"4. Calculating cross-correlation...\")\n",
    "            results['correlation'] = self.calculate_cross_correlation(reference_channel)\n",
    "            \n",
    "            print(\"5. Calculating coherence...\")\n",
    "            results['coherence'] = self.calculate_coherence(reference_channel)\n",
    "        \n",
    "        # 6. Artifact Detection\n",
    "        print(\"6. Detecting artifacts...\")\n",
    "        results['artifacts'] = self.detect_artifacts()\n",
    "        \n",
    "        # 7. Overall Quality Score\n",
    "        results['quality_summary'] = self._calculate_overall_quality_score(results)\n",
    "        \n",
    "        print(\"Assessment complete!\")\n",
    "        self.results = results\n",
    "        return results\n",
    "    \n",
    "    def _calculate_overall_quality_score(self, results):\n",
    "        \"\"\"Calculate overall quality score based on multiple metrics.\"\"\"\n",
    "        quality_scores = []\n",
    "        \n",
    "        for ch in self.ear_channels:\n",
    "            ch_scores = []\n",
    "            \n",
    "            # RMS stability score\n",
    "            if 'rms' in results:\n",
    "                ch_scores.append(results['rms'][ch]['stability_score'])\n",
    "            \n",
    "            # SNR score (normalized)\n",
    "            if 'snr' in results:\n",
    "                snr_db = results['snr'][ch]['snr_db']\n",
    "                snr_score = min(1.0, max(0.0, (snr_db + 10) / 20))  # -10 to 10 dB range\n",
    "                ch_scores.append(snr_score)\n",
    "            \n",
    "            # Artifact score\n",
    "            if 'artifacts' in results:\n",
    "                ch_scores.append(results['artifacts'][ch]['data_quality_score'])\n",
    "            \n",
    "            # Correlation score (if available)\n",
    "            if 'correlation' in results and ch in results['correlation']:\n",
    "                corr_score = abs(results['correlation'][ch]['pearson_r'])\n",
    "                ch_scores.append(corr_score)\n",
    "            \n",
    "            overall_score = np.mean(ch_scores) if ch_scores else 0.0\n",
    "            quality_scores.append({\n",
    "                'channel': ch,\n",
    "                'overall_score': overall_score,\n",
    "                'quality_grade': self._grade_quality(overall_score),\n",
    "            })\n",
    "        \n",
    "        return quality_scores\n",
    "\n",
    "    # ----------------- Visualization methods -----------------\n",
    "    def plot_quality_summary(self, results=None, figsize=(10, 4), palette=None, show=True):\n",
    "        \"\"\"Plot overall quality scores as a bar chart.\n",
    "\n",
    "        Expects results['quality_summary'] to be a list of dicts with keys\n",
    "        'channel' and 'overall_score'. If results is None, uses self.results.\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            results = getattr(self, 'results', None)\n",
    "        if not results or 'quality_summary' not in results:\n",
    "            raise ValueError(\"No quality_summary available in results. Run comprehensive_quality_assessment first or pass results.\")\n",
    "\n",
    "        qs = results['quality_summary']\n",
    "        channels = [q['channel'] for q in qs]\n",
    "        scores = [q['overall_score'] for q in qs]\n",
    "        grades = [q.get('quality_grade', '') for q in qs]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        if palette is None:\n",
    "            palette = sns.color_palette('viridis', len(scores))\n",
    "        sns.barplot(x=scores, y=channels, palette=palette)\n",
    "        plt.xlabel('Overall Quality Score')\n",
    "        plt.ylabel('Channel')\n",
    "        plt.title('EEG Channel Quality Summary')\n",
    "        for i, (s, g) in enumerate(zip(scores, grades)):\n",
    "            plt.text(s + 0.01, i, f\"{g} ({s:.2f})\", va='center')\n",
    "        plt.xlim(0, 1)\n",
    "        if show:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_rms_stability(self, results=None, channels=None, figsize=(12, 4), show=True):\n",
    "        \"\"\"Plot RMS windows for channels or boxplot of stability.\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            results = getattr(self, 'results', None)\n",
    "        if not results or 'rms' not in results:\n",
    "            raise ValueError(\"No rms results available. Run comprehensive_quality_assessment first or pass results.\")\n",
    "\n",
    "        rms = results['rms']\n",
    "        if channels is None:\n",
    "            channels = list(rms.keys())\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        # plot each channel's rms windows as a line\n",
    "        for ch in channels:\n",
    "            windows = rms[ch]['rms_windows']\n",
    "            plt.plot(windows, label=ch)\n",
    "        plt.xlabel('Window #')\n",
    "        plt.ylabel('RMS (V)')\n",
    "        plt.title('RMS windows by channel')\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        if show:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_snr(self, results=None, figsize=(10, 4), show=True):\n",
    "        \"\"\"Plot SNR (dB) per channel as a horizontal bar chart.\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            results = getattr(self, 'results', None)\n",
    "        if not results or 'snr' not in results:\n",
    "            raise ValueError(\"No snr results available. Run comprehensive_quality_assessment first or pass results.\")\n",
    "\n",
    "        snr = results['snr']\n",
    "        channels = list(snr.keys())\n",
    "        snr_db = [snr[ch]['snr_db'] for ch in channels]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.barplot(x=snr_db, y=channels, palette='magma')\n",
    "        plt.xlabel('SNR (dB)')\n",
    "        plt.title('SNR per channel')\n",
    "        if show:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_artifact_proportions(self, results=None, figsize=(10, 4), show=True):\n",
    "        \"\"\"Plot artifact proportion or data quality score per channel.\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            results = getattr(self, 'results', None)\n",
    "        if not results or 'artifacts' not in results:\n",
    "            raise ValueError(\"No artifacts results available. Run comprehensive_quality_assessment first or pass results.\")\n",
    "\n",
    "        art = results['artifacts']\n",
    "        channels = list(art.keys())\n",
    "        proportions = [art[ch]['artifact_proportion'] for ch in channels]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.barplot(x=proportions, y=channels, palette='rocket')\n",
    "        plt.xlabel('Artifact Proportion')\n",
    "        plt.title('Artifact proportion by channel (higher = worse)')\n",
    "        plt.xlim(0, 1)\n",
    "        if show:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def _grade_quality(self, score):\n",
    "        \"\"\"Convert quality score to letter grade.\"\"\"\n",
    "        if score >= 0.8:\n",
    "            return 'A - Excellent'\n",
    "        elif score >= 0.6:\n",
    "            return 'B - Good'\n",
    "        elif score >= 0.4:\n",
    "            return 'C - Fair'\n",
    "        elif score >= 0.2:\n",
    "            return 'D - Poor'\n",
    "        else:\n",
    "            return 'F - Unacceptable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "data = pyxdf.load_xdf(\n",
    "    \"exp_data/02_Experimental/EXP03/sub-198651/sub-198651_task-hearing_run-001.xdf\"\n",
    ")\n",
    "stream = data[0][2]\n",
    "# signals = np.array(stream[\"time_series\"])[:, :-2]\n",
    "signals = np.array(stream[\"time_series\"])\n",
    "timestamps = np.array(stream[\"time_stamps\"])\n",
    "ch_labels = ['L1', 'L2', 'L4', 'L5', 'L7', 'L8', 'L9', 'L10',\n",
    "                 'R1', 'R2', 'R4', 'R5', 'R7', 'R8', 'R9', 'R10']\n",
    "# ch_labels = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"L6\", \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", \"R6\"]\n",
    "\n",
    "sampling_rate = float(stream[\"info\"][\"effective_srate\"])\n",
    "# Openbci EEG data is in microvolts, convert to volts for MNE\n",
    "eeg_data = signals.T * 1e-6\n",
    "info = mne.create_info(ch_names=ch_labels, sfreq=sampling_rate, ch_types=\"eeg\")\n",
    "raw = mne.io.RawArray(eeg_data, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_analyzer = EEGSignalQuality(raw, ch_labels, None)\n",
    "results = quality_analyzer.comprehensive_quality_assessment(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "for summary in results[\"quality_summary\"]:\n",
    "    print(\n",
    "        f\"Channel {summary['channel']}: {summary['quality_grade']} (Score: {summary['overall_score']:.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plots for the computed results\n",
    "try:\n",
    "    # methods will use self.results stored on the analyzer if results not passed explicitly\n",
    "    quality_analyzer.plot_quality_summary()\n",
    "    quality_analyzer.plot_rms_stability()\n",
    "    quality_analyzer.plot_snr()\n",
    "    quality_analyzer.plot_artifact_proportions()\n",
    "except Exception as e:\n",
    "    print('Plotting failed:', e)\n",
    "    print('Ensure `results` exist (run comprehensive_quality_assessment) and plotting libraries are installed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
